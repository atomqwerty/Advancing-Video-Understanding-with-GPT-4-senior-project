<scene: 12 timestamp: 00:10:54.467 - 00:11:55.667> 
Phone recognition on the TIMIT benchmark
(Mohamed, Dahl, & Hinton, 2012)
183 HMM-state labels
not pre-trained
2000 logistic hidden units
5 more layers of
pre-trained weights
2000 logistic hidden units
2000 logstic hidden units
15 frames of 40 filterbank outputs
+ their temporal derivatives
-
-
-
After standard post-processing
using a bi-phone model, a deep
net with 8 layers gets 20.7% error
rate.
The best previous speaker-
independent result on TIMIT was
24.4% and this required averaging
several models.
Li Deng (at MSR) realised that this
result could change the way
speech recognition was done.
<utterances>
 <utterance number= 102 start=0:10:55 end= 0:11:08
 So, Dalam Muhammad developed a system that uses many layers of binary neurons.
<utterance number= 103 start=0:11:08 end= 0:11:14
 To take some acoustic frames and make bets about the labels.
<utterance number= 104 start=0:11:14 end= 0:11:19
 They were doing it on a fairly small database and they are used 183 alternative labels.
<utterance number= 105 start=0:11:19 end= 0:11:25
 And to get this system to well, they did some pre-training which will be described in the second half of the course.
<utterance number= 106 start=0:11:25 end= 0:11:35
 After standard post-processing, they got 20.7% error rate on a very standard benchmark, which is kind of like the M-nist for speech.
<utterance number= 107 start=0:11:35 end= 0:11:41
 The best previous result on that benchmark for speaker independent recognition was 24.4%.
<utterance number= 108 start=0:11:41 end= 0:11:54
 And the very experience for speech researcher at Microsoft Research realized that that was a big enough improvement that probably this would change the way speech recognition systems were done.
<utterance number= 109 start=0:11:54 end= 0:11:56
 And indeed it has.

</utterance>
</scene>
</lecture>
</course>