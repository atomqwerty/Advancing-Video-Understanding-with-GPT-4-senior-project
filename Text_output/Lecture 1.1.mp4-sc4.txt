Scene: 4 timestamp: 00:02:22.200 - 00:03:27.533 
Phone recognition on the TIMIT benchmark
(Mohamed, Dahl, & Hinton, 2012)
183 HMM-state labels
not pre-trained
2000 logistic hidden units
5 more layers of
pre-trained weights
2000 logistic hidden units
2000 logstic hidden units
15 frames of 40 filterbank outputs
+ their temporal derivatives
-
-
-
After standard post-processing
using a bi-phone model, a deep
net with 8 layers gets 20.7% error
rate.
The best previous speaker-
independent result on TIMIT was
24.4% and this required averaging
several models.
Li Deng (at MSR) realised that this
result could change the way
speech recognition was done.
<utterances>
 <utterance number= 33 start=0:02:23 end= 0:02:27
 Some examples of the things that are best done by using a learning algorithm are
<utterance number= 34 start=0:02:27 end= 0:02:29
 recognizing data.
<utterance number= 35 start=0:02:29 end= 0:02:33
 There's also recognizing patterns. So, for example, objects in real scenes.
<utterance number= 36 start=0:02:33 end= 0:02:37
 Or the identities or expressions of people's faces.
<utterance number= 37 start=0:02:37 end= 0:02:44
 Or spoken words. There's also recognizing anomalies.
<utterance number= 38 start=0:02:44 end= 0:02:49
 So, an unusual sequence of credit card transactions would be an anomaly.
<utterance number= 39 start=0:02:49 end= 0:02:54
 Another example of an anomaly would be an unusual pattern of sensor readings in a
<utterance number= 40 start=0:02:54 end= 0:02:57
 nuclear power plant. And you wouldn't really want to have to
<utterance number= 41 start=0:02:57 end= 0:02:59
 deal with those by doing sequence analysis.
<utterance number= 42 start=0:02:59 end= 0:03:02
 And then there's supervised learning where you look at the ones that blow up
<utterance number= 43 start=0:03:02 end= 0:03:06
 and see what, what caused them to blow up. You'd really like to recognize that
<utterance number= 44 start=0:03:06 end= 0:03:10
 something funny is happening without having any supervision signal.
<utterance number= 45 start=0:03:10 end= 0:03:15
 It's just not behaving in its normal way. And then there's prediction.
<utterance number= 46 start=0:03:15 end= 0:03:20
 So, typically predicting future stock prices or currency exchange rates.
<utterance number= 47 start=0:03:20 end= 0:03:24
 Or predicting which movies a person will like from knowing which other movies they
<utterance number= 48 start=0:03:24 end= 0:03:27
 like and which movies a lot of other people liked.
<utterance number= 49 start=0:03:27 end= 0:03:33
 So, in this course, I'm going to use a standard example for explaining a lot of

</utterance>
</scene>
</lecture>
</course>